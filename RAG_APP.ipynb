{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNd2CV1/9JQevco8ncS+DfE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SurajMegharaj/QA--RAG-app/blob/main/RAG_APP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installations"
      ],
      "metadata": {
        "id": "QAwUTqy33PCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "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"
      ],
      "metadata": {
        "id": "KWq8Gg7b5n7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "!pip install -U langchain-community\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE4dkvEX3TGK",
        "outputId": "860f669c-1e4f-45e2-93f8-16a9e35b3922"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.34)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.18 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.6)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Dataset"
      ],
      "metadata": {
        "id": "rXSapvLE2MKf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weA14zEs1_8k",
        "outputId": "00cefcc3-e227-4ee4-b322-2effd9af74f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded document preview:\n",
            "AWS VS AZURE VS GCP: COMPARING THE BIG 3 CLOUD\n",
            "PLATFORMS\n",
            "The big three of cloud computing platforms\n",
            "Cloud computing  has revolutionized the way organizations handle digital operations. Amazon Web\n",
            "Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) are the three cloud service\n",
            "providers  dominating the cloud market worldwide.\n",
            "Most enterprises have moved computing from on-site servers into the cloud and even multi-cloud\n",
            "environments , so that they can benefit from features such as:\n",
            "Dec\n"
          ]
        }
      ],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# File path to your PDF\n",
        "file_path = \"/content/aws-vs-azure-vs-gcp-comparing-the-big-3-cloud-platforms.pdf\"\n",
        "\n",
        "# Initialize PdfReader\n",
        "reader = PdfReader(file_path)\n",
        "\n",
        "# Extract text from all pages\n",
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "    text += page.extract_text()\n",
        "\n",
        "# Now that you've extracted text, let's prepare the document for RAG\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Load the extracted text into the document\n",
        "document = Document(page_content=text)\n",
        "\n",
        "# Optionally, print the first few lines of the document to verify\n",
        "print(\"Loaded document preview:\")\n",
        "print(document.page_content[:500])  # Display the first 500 characters\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Using a pre-trained model to generate embeddings (vector representations)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "document = Document(page_content=text)\n",
        "documents = [document]\n",
        "\n",
        "# Index documents using FAISS\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)\n"
      ],
      "metadata": {
        "id": "7r4-Krpu2y6N"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "# Initialize the language model (e.g., GPT from Hugging Face)\n",
        "llm = HuggingFaceHub(repo_id=\"gpt2\", model_kwargs={\"temperature\": 0.5, \"max_length\": 150},huggingfacehub_api_token=\"Enter your Api token\")\n"
      ],
      "metadata": {
        "id": "HtM8kPaf3gZs"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Assuming llm is your language model and vectorstore (like FAISS) is ready\n",
        "\n",
        "# Use the retriever from the vectorstore\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Create the retrieval-based QA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,  # Your language model\n",
        "    chain_type=\"stuff\",  # Standard chain type for retrieval-based QA\n",
        "    retriever=retriever,  # Use the retriever from vectorstore\n",
        "    return_source_documents=True  # Optionally return source documents\n",
        ")\n",
        "\n",
        "# Test with a query\n",
        "query = \"3 big platforms are\"\n",
        "# Use invoke() to get the full output\n",
        "response = qa_chain.invoke({\"query\": query})\n",
        "\n",
        "# Extract the result and source documents\n",
        "result = response[\"result\"]\n",
        "source_documents = response[\"source_documents\"]\n",
        "\n",
        "# Print the response\n",
        "print(\"Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sgqq_d-4y_J",
        "outputId": "1cb8f807-6ade-4471-8248-d964baeca531"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: {'query': '3 big platforms are', 'result': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nAWS VS AZURE VS GCP: COMPARING THE BIG 3 CLOUD\\nPLATFORMS\\nThe big three of cloud computing platforms\\nCloud computing  has revolutionized the way organizations handle digital operations. Amazon Web\\nServices (AWS), Microsoft Azure, and Google Cloud Platform (GCP) are the three cloud service\\nproviders  dominating the cloud market worldwide.\\nMost enterprises have moved computing from on-site servers into the cloud and even multi-cloud\\nenvironments , so that they can benefit from features such as:\\nDecreased CapEx\\nReduced infrastructure maintenance\\nIncreased availability  and reliability\\nScalability of an on-demand resource\\nLower operational costs\\nRemote access and facilitated collaboration\\nSupport for multiple devices\\nOptimized infrastructure for speed and performance\\nEnhanced security\\nAccess to the most up-to-date technologyThe big three cloud computing providers all bring experience and expertise to their reliable and\\nfeature-rich platforms. Which is better? AWS vs Microsoft Azure vs Google Cloud?\\nHere are details of each one, along with an Azure, AWS, and GCP comparison that will help you do\\nyour due diligence before making a choice for your company.\\nAmazon Web Services (AWS)\\nMicrosoft Azure\\nGoogle Cloud Platform (GCP)\\nHow to choose between AWS, Microsoft Azure, and Google Cloud\\nUnderstanding Pricing Differences Between AWS, GCP, and Microsoft Azure\\nPros and Cons of AWS, Azure, and GCP\\nAmazon Web Services (AWS)\\nThe current market leader is Amazon Web Services , a subsidiary of Amazon.com, Inc. It is the most\\nmature cloud platform and offers a wide range of services to individual developers, small and large\\nenterprises, and governments.\\nAWS started its life as an internal cloud platform. It evolved into a publicly available, on-demand\\ninternet computing resource in 2006, offering services like Amazon S3 cloud storage and elastic\\ncompute cloud (EC2). AWS now offers more than 200 fully featured services to millions of users. It\\nrakes in one of every three dollars spent on cloud services, with an annual growth rate of 37%,\\naccording to figures published in The Register . It delivered 54% of Amazon’s total operating income  in\\n2023.\\nProminent AWS customers include:\\nExpedia\\nNetflix\\nCoinbase\\nFormula 1\\nCoca Cola\\nIntuit\\nAirbnb\\nLyftCoursera\\nFood and Drug Administration (FDA)\\n(Explore our AWS Guide , a series of articles & tutorials.)\\nMicrosoft Azure\\nMicrosoft Azure is the second-largest cloud platform, but is growing faster than AWS with an annual\\ngrowth rate of 46%, again as measured in The Register . Microsoft has reported  cloud revenue growth\\nof 30% for the quarter ending December 31, 2023. Azure has expanded since its 2010 launch to offer\\nover 200 products and services. \\nAzure, an offering of Microsoft, is particularly tailored to support Microsoft-centric enterprises.\\nMoving to the cloud or a hybrid-cloud environment is easier for these organizations. More than 95%\\nof Fortune 500  companies use Microsoft Azure today.\\nAzure is not limited to Windows-based services. It also supports open-source languages,\\ntechnologies, and platforms, giving anyone the freedom to build and support any application.\\nWell known Azure customers include:\\nDAIMLER AG\\nMcKesson Group\\nAsos\\nCenter of Disease Control (CDC) – US\\nNational Health Service (NHS) – UK\\nHSBC\\nStarbucks\\nWalgreens\\n3M\\nHP\\nMitsubishi Electric\\nRenault\\n(Explore popular Azure certifications .)\\nGoogle Cloud Platform (GCP)\\nCompared to AWS vs Azure, GCP is the smallest of the big three cloud providers.\\nThat said, it is the fastest growing, with a 54% market share growth rate, The Register reports. The\\ncompany expects  the business to grow 20% in 2024.\\nThe GCP currently offers over 200 services spanning computing, networking, big data , and more.\\nToday, GCP consists of services including Google Workspace, enterprise Android, and Chrome OS.\\nNotable GCP customers include:\\nToyota\\nUnilever\\nNintendo\\nSpotifyThe Home Depot\\nTarget\\nTwitter\\nPaypal\\nUPS\\nHow to choose between AWS, Microsoft Azure, and Google Cloud\\nWhen choosing between AWS vs. Microsoft Azure vs. Google Cloud, the first thing to consider is the\\navailability of services in the regions where you operate. Regional availability has a direct impact on\\nperformance, like network latency and speed in transmitting data. Compliance issues also vary by\\nregion, particularly related to cybersecurity.\\nAs of July 25, 2024, here’s where the big three stand:\\nComparing AWS, GCP, and Azure regions and availability\\nWhen choosing a cloud provider, the first thing to consider is its supported regions and availability.\\nThese directly impact the performance of your cloud, due to factors like latency and compliance\\nrequirements, especially when dealing with data.\\nAs of September 2021, here’s where the Big 3 stand:\\nAWS  has 33 geographic regions  with105 availability zones. They plan to add seven more\\nregions and 21 more availability zones in the immediate future. They serve 600+ edge locations\\nand 12 regional edge caches.\\nMicrosoft Azure  runs 64 regions  with 15 under construction. They maintain 126 availability\\nzones with 37 more being built. Microsoft maintains  192 edge locations in global cities with four\\nedge locations in the US government cloud.\\nGCP  has 40 cloud regions  with eight new ones coming soon. They’ve built 121 zones and 187\\nedge locations.\\nEach of these platforms provide specialized cloud solutions for the government (government cloud).\\nBoth AWS and Azure offer specialized services that cater to the Chinese market as well, with data\\ncenters located in China.\\nIn making an Azure, AWS, and GCP comparison, it’s important to note that each covers most of the\\nglobe. All three are also continuing to expand their coverage by adding more regions and zones to\\nmeet the ever-increasing computing demand.\\n(Get an in-depth look at the Big 3 regions & availability .)\\nCommon services of the big three cloud providers\\nAn AWS vs. Azure comparison shows that both have similarly large catalogs of more than 200\\nservices each. GCP is quickly catching up to these leaders. A general breakdown of services is:\\nAWS has the largest catalog of services, topping 250.\\nAzure is a close second, with an impressive set of over 200 artificial intelligence (AI), machine\\nlearning (ML), and analytics services.\\nGCP matches Azure in the number of services they offer.Here are the common service offerings of each cloud platform.\\nComparing AWS, Azure, and GCP compute services\\nThis Azure, AWS, GCP comparison of services chart shows how they compete with various\\ntechnologies across key offerings.\\nComparing AWS, Azure, and GCP database and storage services\\nWhen it comes to storage services, AWS, Azure, and GCP also compete with different database\\ntechnologies and branded storage solutions.Comparing AWS, Azure, and GCP networking services\\nComparing AWS, Azure, and GCP, each has their own way of handling various aspects of managing\\nnetworking services.An\\nAzure, AWS, and GCP comparison shows that they all cover common computing needs. Their\\ndifferences fall into two categories:\\nHow each service is implemented in its cloud platform\\nThe individual features available for each service\\nSpecialized services\\nAn area of significant service differences between AWS, Microsoft Azure, and Google Cloud is in\\nspecialized services. AWS and Azure are comparable, with GCP rapidly catching up.Thes\\ne are only some of the specialized services available on these platforms. AWS customers can even\\ndabble with quantum computing using Amazon Braket .Understanding pricing differences between AWS, GCP, and Microsoft Azure\\nAWS vs Microsoft Azure vs Google Cloud compete on both price and value. Their pricing plans are\\nbased on these factors:\\nCustomer requirements\\nUsage\\nServices used\\nAll three platforms offer competitive pricing plans with additional cost management\\noptions—reserved instances, budgets, and resource optimization—available to all users.\\nThe consensus in the IT community is that Microsoft Azure currently has the lowest on-demand\\npricing, while Amazon tends to come in somewhere around the middle. Enterprise customers\\nalready using Microsoft services (Windows, active directory, MS SQL, etc.) have an advantage when\\nthey move to Azure, as it is significantly cheaper than other cloud providers.\\nEvaluating the big three\\nIn evaluating AWS vs. Azure vs. GCP, you will find that each has pros and cons. We’ve simplified the\\ncomparison for you here:AWS: Pros and Cons\\nAWS: Pros and Cons\\nPros Cons\\n• Most services available, from networking to\\nrobotics\\n• Most mature\\n• Considered the gold standard in cloud reliability\\nand security\\n• More compute capacity vs Azure & GCP\\n• All major software vendors make their programs\\navailable on AWS• Dev/Enterprise support must be purchased\\n• Can overwhelm newcomers with the sheer\\nnumber of services and options\\n• Comparatively limited options for hybrid cloud\\nMICROSOFT AZURE: Pros and Cons\\nPros Cons\\n• Easy integration and migrations for existing\\nMicrosoft services\\n• Many services available, including best-in-class\\nAI, ML, and analytics services\\n• Relatively cheaper for most services vs AWS &\\nGCP\\n• Great support for hybrid cloud strategies• Fewer service offerings vs AWS\\n• Particularly geared towards enterprise\\ncustomers\\nGCP: Pros and Cons\\nPros Cons\\n• Plays nicely with other Google service and\\nproducts\\n• Excellent support for containerized workloads\\n• Global fiber network• Limited services vs AWS & Azure\\n• Limited support for enterprise use casesSumming up the differences between AWS, Azure, and Google Cloud\\nThough AWS is the current market leader in terms of capacity and service, Microsoft and Google are\\ngrowing quickly to challenge that dominance. To compete with AWS, they are building out facilities,\\ninnovating new services, and offering new options in their packages and pricing plans.\\nMicrosoft is challenging AWS by going after the large enterprise market segment. Google is\\ndifferentiating with multiple integrated open-source projects and third-party services.\\nWhich is right for your company? In making an Azure, AWS, GCP comparison, the right answer\\ndepends on your specific use case. In a rapidly evolving cloud technology environment, more\\ncustomers are implementing multi-cloud strategies to make the best use of each provider’s\\nstrengths, without locking themselves to a single one .\\n\\nQuestion: 3 big platforms are\\nHelpful Answer: AWS (Amazon Web Services), Azure (Microsoft Azure), and GCP (Google Cloud Platform)\", 'source_documents': [Document(id='b77109fd-ea01-48e3-95af-77431122b0c1', metadata={}, page_content='AWS VS AZURE VS GCP: COMPARING THE BIG 3 CLOUD\\nPLATFORMS\\nThe big three of cloud computing platforms\\nCloud computing  has revolutionized the way organizations handle digital operations. Amazon Web\\nServices (AWS), Microsoft Azure, and Google Cloud Platform (GCP) are the three cloud service\\nproviders  dominating the cloud market worldwide.\\nMost enterprises have moved computing from on-site servers into the cloud and even multi-cloud\\nenvironments , so that they can benefit from features such as:\\nDecreased CapEx\\nReduced infrastructure maintenance\\nIncreased availability  and reliability\\nScalability of an on-demand resource\\nLower operational costs\\nRemote access and facilitated collaboration\\nSupport for multiple devices\\nOptimized infrastructure for speed and performance\\nEnhanced security\\nAccess to the most up-to-date technologyThe big three cloud computing providers all bring experience and expertise to their reliable and\\nfeature-rich platforms. Which is better? AWS vs Microsoft Azure vs Google Cloud?\\nHere are details of each one, along with an Azure, AWS, and GCP comparison that will help you do\\nyour due diligence before making a choice for your company.\\nAmazon Web Services (AWS)\\nMicrosoft Azure\\nGoogle Cloud Platform (GCP)\\nHow to choose between AWS, Microsoft Azure, and Google Cloud\\nUnderstanding Pricing Differences Between AWS, GCP, and Microsoft Azure\\nPros and Cons of AWS, Azure, and GCP\\nAmazon Web Services (AWS)\\nThe current market leader is Amazon Web Services , a subsidiary of Amazon.com, Inc. It is the most\\nmature cloud platform and offers a wide range of services to individual developers, small and large\\nenterprises, and governments.\\nAWS started its life as an internal cloud platform. It evolved into a publicly available, on-demand\\ninternet computing resource in 2006, offering services like Amazon S3 cloud storage and elastic\\ncompute cloud (EC2). AWS now offers more than 200 fully featured services to millions of users. It\\nrakes in one of every three dollars spent on cloud services, with an annual growth rate of 37%,\\naccording to figures published in The Register . It delivered 54% of Amazon’s total operating income  in\\n2023.\\nProminent AWS customers include:\\nExpedia\\nNetflix\\nCoinbase\\nFormula 1\\nCoca Cola\\nIntuit\\nAirbnb\\nLyftCoursera\\nFood and Drug Administration (FDA)\\n(Explore our AWS Guide , a series of articles & tutorials.)\\nMicrosoft Azure\\nMicrosoft Azure is the second-largest cloud platform, but is growing faster than AWS with an annual\\ngrowth rate of 46%, again as measured in The Register . Microsoft has reported  cloud revenue growth\\nof 30% for the quarter ending December 31, 2023. Azure has expanded since its 2010 launch to offer\\nover 200 products and services. \\nAzure, an offering of Microsoft, is particularly tailored to support Microsoft-centric enterprises.\\nMoving to the cloud or a hybrid-cloud environment is easier for these organizations. More than 95%\\nof Fortune 500  companies use Microsoft Azure today.\\nAzure is not limited to Windows-based services. It also supports open-source languages,\\ntechnologies, and platforms, giving anyone the freedom to build and support any application.\\nWell known Azure customers include:\\nDAIMLER AG\\nMcKesson Group\\nAsos\\nCenter of Disease Control (CDC) – US\\nNational Health Service (NHS) – UK\\nHSBC\\nStarbucks\\nWalgreens\\n3M\\nHP\\nMitsubishi Electric\\nRenault\\n(Explore popular Azure certifications .)\\nGoogle Cloud Platform (GCP)\\nCompared to AWS vs Azure, GCP is the smallest of the big three cloud providers.\\nThat said, it is the fastest growing, with a 54% market share growth rate, The Register reports. The\\ncompany expects  the business to grow 20% in 2024.\\nThe GCP currently offers over 200 services spanning computing, networking, big data , and more.\\nToday, GCP consists of services including Google Workspace, enterprise Android, and Chrome OS.\\nNotable GCP customers include:\\nToyota\\nUnilever\\nNintendo\\nSpotifyThe Home Depot\\nTarget\\nTwitter\\nPaypal\\nUPS\\nHow to choose between AWS, Microsoft Azure, and Google Cloud\\nWhen choosing between AWS vs. Microsoft Azure vs. Google Cloud, the first thing to consider is the\\navailability of services in the regions where you operate. Regional availability has a direct impact on\\nperformance, like network latency and speed in transmitting data. Compliance issues also vary by\\nregion, particularly related to cybersecurity.\\nAs of July 25, 2024, here’s where the big three stand:\\nComparing AWS, GCP, and Azure regions and availability\\nWhen choosing a cloud provider, the first thing to consider is its supported regions and availability.\\nThese directly impact the performance of your cloud, due to factors like latency and compliance\\nrequirements, especially when dealing with data.\\nAs of September 2021, here’s where the Big 3 stand:\\nAWS  has 33 geographic regions  with105 availability zones. They plan to add seven more\\nregions and 21 more availability zones in the immediate future. They serve 600+ edge locations\\nand 12 regional edge caches.\\nMicrosoft Azure  runs 64 regions  with 15 under construction. They maintain 126 availability\\nzones with 37 more being built. Microsoft maintains  192 edge locations in global cities with four\\nedge locations in the US government cloud.\\nGCP  has 40 cloud regions  with eight new ones coming soon. They’ve built 121 zones and 187\\nedge locations.\\nEach of these platforms provide specialized cloud solutions for the government (government cloud).\\nBoth AWS and Azure offer specialized services that cater to the Chinese market as well, with data\\ncenters located in China.\\nIn making an Azure, AWS, and GCP comparison, it’s important to note that each covers most of the\\nglobe. All three are also continuing to expand their coverage by adding more regions and zones to\\nmeet the ever-increasing computing demand.\\n(Get an in-depth look at the Big 3 regions & availability .)\\nCommon services of the big three cloud providers\\nAn AWS vs. Azure comparison shows that both have similarly large catalogs of more than 200\\nservices each. GCP is quickly catching up to these leaders. A general breakdown of services is:\\nAWS has the largest catalog of services, topping 250.\\nAzure is a close second, with an impressive set of over 200 artificial intelligence (AI), machine\\nlearning (ML), and analytics services.\\nGCP matches Azure in the number of services they offer.Here are the common service offerings of each cloud platform.\\nComparing AWS, Azure, and GCP compute services\\nThis Azure, AWS, GCP comparison of services chart shows how they compete with various\\ntechnologies across key offerings.\\nComparing AWS, Azure, and GCP database and storage services\\nWhen it comes to storage services, AWS, Azure, and GCP also compete with different database\\ntechnologies and branded storage solutions.Comparing AWS, Azure, and GCP networking services\\nComparing AWS, Azure, and GCP, each has their own way of handling various aspects of managing\\nnetworking services.An\\nAzure, AWS, and GCP comparison shows that they all cover common computing needs. Their\\ndifferences fall into two categories:\\nHow each service is implemented in its cloud platform\\nThe individual features available for each service\\nSpecialized services\\nAn area of significant service differences between AWS, Microsoft Azure, and Google Cloud is in\\nspecialized services. AWS and Azure are comparable, with GCP rapidly catching up.Thes\\ne are only some of the specialized services available on these platforms. AWS customers can even\\ndabble with quantum computing using Amazon Braket .Understanding pricing differences between AWS, GCP, and Microsoft Azure\\nAWS vs Microsoft Azure vs Google Cloud compete on both price and value. Their pricing plans are\\nbased on these factors:\\nCustomer requirements\\nUsage\\nServices used\\nAll three platforms offer competitive pricing plans with additional cost management\\noptions—reserved instances, budgets, and resource optimization—available to all users.\\nThe consensus in the IT community is that Microsoft Azure currently has the lowest on-demand\\npricing, while Amazon tends to come in somewhere around the middle. Enterprise customers\\nalready using Microsoft services (Windows, active directory, MS SQL, etc.) have an advantage when\\nthey move to Azure, as it is significantly cheaper than other cloud providers.\\nEvaluating the big three\\nIn evaluating AWS vs. Azure vs. GCP, you will find that each has pros and cons. We’ve simplified the\\ncomparison for you here:AWS: Pros and Cons\\nAWS: Pros and Cons\\nPros Cons\\n• Most services available, from networking to\\nrobotics\\n• Most mature\\n• Considered the gold standard in cloud reliability\\nand security\\n• More compute capacity vs Azure & GCP\\n• All major software vendors make their programs\\navailable on AWS• Dev/Enterprise support must be purchased\\n• Can overwhelm newcomers with the sheer\\nnumber of services and options\\n• Comparatively limited options for hybrid cloud\\nMICROSOFT AZURE: Pros and Cons\\nPros Cons\\n• Easy integration and migrations for existing\\nMicrosoft services\\n• Many services available, including best-in-class\\nAI, ML, and analytics services\\n• Relatively cheaper for most services vs AWS &\\nGCP\\n• Great support for hybrid cloud strategies• Fewer service offerings vs AWS\\n• Particularly geared towards enterprise\\ncustomers\\nGCP: Pros and Cons\\nPros Cons\\n• Plays nicely with other Google service and\\nproducts\\n• Excellent support for containerized workloads\\n• Global fiber network• Limited services vs AWS & Azure\\n• Limited support for enterprise use casesSumming up the differences between AWS, Azure, and Google Cloud\\nThough AWS is the current market leader in terms of capacity and service, Microsoft and Google are\\ngrowing quickly to challenge that dominance. To compete with AWS, they are building out facilities,\\ninnovating new services, and offering new options in their packages and pricing plans.\\nMicrosoft is challenging AWS by going after the large enterprise market segment. Google is\\ndifferentiating with multiple integrated open-source projects and third-party services.\\nWhich is right for your company? In making an Azure, AWS, GCP comparison, the right answer\\ndepends on your specific use case. In a rapidly evolving cloud technology environment, more\\ncustomers are implementing multi-cloud strategies to make the best use of each provider’s\\nstrengths, without locking themselves to a single one .')]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, RetrievalQA\n",
        "\n",
        "# Create the LLM prompt for summarization\n",
        "llm_prompt = PromptTemplate(\n",
        "    input_variables=[\"context\"],\n",
        "    template=\"Summarize the following content:\\n\\n{context}\\n\\nSummary:\"\n",
        ")\n",
        "\n",
        "# Create the LLM chain for summarization\n",
        "llm_chain = LLMChain(llm=llm, prompt=llm_prompt)\n",
        "\n",
        "# Create a basic retrieval QA chain with summarization\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",  # This will use a 'StuffDocumentsChain' internally.\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# Test the system with a query\n",
        "query = \"What is AWS?\"\n",
        "response = qa_chain({\"query\": query})\n",
        "\n",
        "# Inspect the structure of the response\n",
        "print(response)\n",
        "\n",
        "# Extract the actual summarized response\n",
        "# We assume `response` has 'result' and 'source_documents' keys\n",
        "\n",
        "if 'result' in response:\n",
        "    result = response['result']  # Get the result\n",
        "\n",
        "    # Print the result part\n",
        "    print(\"Summarized Response:\", result)\n",
        "\n",
        "    # If there are source documents, we can choose to ignore them\n",
        "    if 'source_documents' in response:\n",
        "        print(\"\\nNote: Ignoring source document content...\")\n",
        "        for doc in response['source_documents']:\n",
        "            # Example: Only show the metadata of the source docs, not the full text\n",
        "            print(\"Source Document Metadata:\", doc.metadata)\n",
        "else:\n",
        "    print(\"No summarized result found.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOrykKI074JD",
        "outputId": "e07c5845-498c-4630-eeb2-6411c058a720"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'What is AWS?', 'result': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nAWS VS AZURE VS GCP: COMPARING THE BIG 3 CLOUD\\nPLATFORMS\\nThe big three of cloud computing platforms\\nCloud computing  has revolutionized the way organizations handle digital operations. Amazon Web\\nServices (AWS), Microsoft Azure, and Google Cloud Platform (GCP) are the three cloud service\\nproviders  dominating the cloud market worldwide.\\nMost enterprises have moved computing from on-site servers into the cloud and even multi-cloud\\nenvironments , so that they can benefit from features such as:\\nDecreased CapEx\\nReduced infrastructure maintenance\\nIncreased availability  and reliability\\nScalability of an on-demand resource\\nLower operational costs\\nRemote access and facilitated collaboration\\nSupport for multiple devices\\nOptimized infrastructure for speed and performance\\nEnhanced security\\nAccess to the most up-to-date technologyThe big three cloud computing providers all bring experience and expertise to their reliable and\\nfeature-rich platforms. Which is better? AWS vs Microsoft Azure vs Google Cloud?\\nHere are details of each one, along with an Azure, AWS, and GCP comparison that will help you do\\nyour due diligence before making a choice for your company.\\nAmazon Web Services (AWS)\\nMicrosoft Azure\\nGoogle Cloud Platform (GCP)\\nHow to choose between AWS, Microsoft Azure, and Google Cloud\\nUnderstanding Pricing Differences Between AWS, GCP, and Microsoft Azure\\nPros and Cons of AWS, Azure, and GCP\\nAmazon Web Services (AWS)\\nThe current market leader is Amazon Web Services , a subsidiary of Amazon.com, Inc. It is the most\\nmature cloud platform and offers a wide range of services to individual developers, small and large\\nenterprises, and governments.\\nAWS started its life as an internal cloud platform. It evolved into a publicly available, on-demand\\ninternet computing resource in 2006, offering services like Amazon S3 cloud storage and elastic\\ncompute cloud (EC2). AWS now offers more than 200 fully featured services to millions of users. It\\nrakes in one of every three dollars spent on cloud services, with an annual growth rate of 37%,\\naccording to figures published in The Register . It delivered 54% of Amazon’s total operating income  in\\n2023.\\nProminent AWS customers include:\\nExpedia\\nNetflix\\nCoinbase\\nFormula 1\\nCoca Cola\\nIntuit\\nAirbnb\\nLyftCoursera\\nFood and Drug Administration (FDA)\\n(Explore our AWS Guide , a series of articles & tutorials.)\\nMicrosoft Azure\\nMicrosoft Azure is the second-largest cloud platform, but is growing faster than AWS with an annual\\ngrowth rate of 46%, again as measured in The Register . Microsoft has reported  cloud revenue growth\\nof 30% for the quarter ending December 31, 2023. Azure has expanded since its 2010 launch to offer\\nover 200 products and services. \\nAzure, an offering of Microsoft, is particularly tailored to support Microsoft-centric enterprises.\\nMoving to the cloud or a hybrid-cloud environment is easier for these organizations. More than 95%\\nof Fortune 500  companies use Microsoft Azure today.\\nAzure is not limited to Windows-based services. It also supports open-source languages,\\ntechnologies, and platforms, giving anyone the freedom to build and support any application.\\nWell known Azure customers include:\\nDAIMLER AG\\nMcKesson Group\\nAsos\\nCenter of Disease Control (CDC) – US\\nNational Health Service (NHS) – UK\\nHSBC\\nStarbucks\\nWalgreens\\n3M\\nHP\\nMitsubishi Electric\\nRenault\\n(Explore popular Azure certifications .)\\nGoogle Cloud Platform (GCP)\\nCompared to AWS vs Azure, GCP is the smallest of the big three cloud providers.\\nThat said, it is the fastest growing, with a 54% market share growth rate, The Register reports. The\\ncompany expects  the business to grow 20% in 2024.\\nThe GCP currently offers over 200 services spanning computing, networking, big data , and more.\\nToday, GCP consists of services including Google Workspace, enterprise Android, and Chrome OS.\\nNotable GCP customers include:\\nToyota\\nUnilever\\nNintendo\\nSpotifyThe Home Depot\\nTarget\\nTwitter\\nPaypal\\nUPS\\nHow to choose between AWS, Microsoft Azure, and Google Cloud\\nWhen choosing between AWS vs. Microsoft Azure vs. Google Cloud, the first thing to consider is the\\navailability of services in the regions where you operate. Regional availability has a direct impact on\\nperformance, like network latency and speed in transmitting data. Compliance issues also vary by\\nregion, particularly related to cybersecurity.\\nAs of July 25, 2024, here’s where the big three stand:\\nComparing AWS, GCP, and Azure regions and availability\\nWhen choosing a cloud provider, the first thing to consider is its supported regions and availability.\\nThese directly impact the performance of your cloud, due to factors like latency and compliance\\nrequirements, especially when dealing with data.\\nAs of September 2021, here’s where the Big 3 stand:\\nAWS  has 33 geographic regions  with105 availability zones. They plan to add seven more\\nregions and 21 more availability zones in the immediate future. They serve 600+ edge locations\\nand 12 regional edge caches.\\nMicrosoft Azure  runs 64 regions  with 15 under construction. They maintain 126 availability\\nzones with 37 more being built. Microsoft maintains  192 edge locations in global cities with four\\nedge locations in the US government cloud.\\nGCP  has 40 cloud regions  with eight new ones coming soon. They’ve built 121 zones and 187\\nedge locations.\\nEach of these platforms provide specialized cloud solutions for the government (government cloud).\\nBoth AWS and Azure offer specialized services that cater to the Chinese market as well, with data\\ncenters located in China.\\nIn making an Azure, AWS, and GCP comparison, it’s important to note that each covers most of the\\nglobe. All three are also continuing to expand their coverage by adding more regions and zones to\\nmeet the ever-increasing computing demand.\\n(Get an in-depth look at the Big 3 regions & availability .)\\nCommon services of the big three cloud providers\\nAn AWS vs. Azure comparison shows that both have similarly large catalogs of more than 200\\nservices each. GCP is quickly catching up to these leaders. A general breakdown of services is:\\nAWS has the largest catalog of services, topping 250.\\nAzure is a close second, with an impressive set of over 200 artificial intelligence (AI), machine\\nlearning (ML), and analytics services.\\nGCP matches Azure in the number of services they offer.Here are the common service offerings of each cloud platform.\\nComparing AWS, Azure, and GCP compute services\\nThis Azure, AWS, GCP comparison of services chart shows how they compete with various\\ntechnologies across key offerings.\\nComparing AWS, Azure, and GCP database and storage services\\nWhen it comes to storage services, AWS, Azure, and GCP also compete with different database\\ntechnologies and branded storage solutions.Comparing AWS, Azure, and GCP networking services\\nComparing AWS, Azure, and GCP, each has their own way of handling various aspects of managing\\nnetworking services.An\\nAzure, AWS, and GCP comparison shows that they all cover common computing needs. Their\\ndifferences fall into two categories:\\nHow each service is implemented in its cloud platform\\nThe individual features available for each service\\nSpecialized services\\nAn area of significant service differences between AWS, Microsoft Azure, and Google Cloud is in\\nspecialized services. AWS and Azure are comparable, with GCP rapidly catching up.Thes\\ne are only some of the specialized services available on these platforms. AWS customers can even\\ndabble with quantum computing using Amazon Braket .Understanding pricing differences between AWS, GCP, and Microsoft Azure\\nAWS vs Microsoft Azure vs Google Cloud compete on both price and value. Their pricing plans are\\nbased on these factors:\\nCustomer requirements\\nUsage\\nServices used\\nAll three platforms offer competitive pricing plans with additional cost management\\noptions—reserved instances, budgets, and resource optimization—available to all users.\\nThe consensus in the IT community is that Microsoft Azure currently has the lowest on-demand\\npricing, while Amazon tends to come in somewhere around the middle. Enterprise customers\\nalready using Microsoft services (Windows, active directory, MS SQL, etc.) have an advantage when\\nthey move to Azure, as it is significantly cheaper than other cloud providers.\\nEvaluating the big three\\nIn evaluating AWS vs. Azure vs. GCP, you will find that each has pros and cons. We’ve simplified the\\ncomparison for you here:AWS: Pros and Cons\\nAWS: Pros and Cons\\nPros Cons\\n• Most services available, from networking to\\nrobotics\\n• Most mature\\n• Considered the gold standard in cloud reliability\\nand security\\n• More compute capacity vs Azure & GCP\\n• All major software vendors make their programs\\navailable on AWS• Dev/Enterprise support must be purchased\\n• Can overwhelm newcomers with the sheer\\nnumber of services and options\\n• Comparatively limited options for hybrid cloud\\nMICROSOFT AZURE: Pros and Cons\\nPros Cons\\n• Easy integration and migrations for existing\\nMicrosoft services\\n• Many services available, including best-in-class\\nAI, ML, and analytics services\\n• Relatively cheaper for most services vs AWS &\\nGCP\\n• Great support for hybrid cloud strategies• Fewer service offerings vs AWS\\n• Particularly geared towards enterprise\\ncustomers\\nGCP: Pros and Cons\\nPros Cons\\n• Plays nicely with other Google service and\\nproducts\\n• Excellent support for containerized workloads\\n• Global fiber network• Limited services vs AWS & Azure\\n• Limited support for enterprise use casesSumming up the differences between AWS, Azure, and Google Cloud\\nThough AWS is the current market leader in terms of capacity and service, Microsoft and Google are\\ngrowing quickly to challenge that dominance. To compete with AWS, they are building out facilities,\\ninnovating new services, and offering new options in their packages and pricing plans.\\nMicrosoft is challenging AWS by going after the large enterprise market segment. Google is\\ndifferentiating with multiple integrated open-source projects and third-party services.\\nWhich is right for your company? In making an Azure, AWS, GCP comparison, the right answer\\ndepends on your specific use case. In a rapidly evolving cloud technology environment, more\\ncustomers are implementing multi-cloud strategies to make the best use of each provider’s\\nstrengths, without locking themselves to a single one .\\n\\nQuestion: What is AWS?\\nHelpful Answer: AWS stands for Amazon Web Services, which is a subsidiary of Amazon.com, Inc. It is the most mature cloud platform and offers a wide range of services to individual developers, small and large enterprises, and governments. AWS started its life as an internal cloud platform and evolved into a publicly available, on-demand internet computing resource in 2006, offering services like Amazon S3 cloud storage and elastic compute cloud (EC2). AWS now offers more than 200 fully featured services to millions of users. It raked in one of every three dollars spent on cloud services, with an annual growth rate of 37%, according to figures published in The Register. It delivered 54% of Amazon’s total operating income in 2023. Prominent AWS customers include Expedia, Netflix, Coinbase, Formula 1, Coca Cola, Intuit, Airbnb, Lyft, Coursera, and the Food and Drug Administration (FDA).\", 'source_documents': [Document(id='b77109fd-ea01-48e3-95af-77431122b0c1', metadata={}, page_content='AWS VS AZURE VS GCP: COMPARING THE BIG 3 CLOUD\\nPLATFORMS\\nThe big three of cloud computing platforms\\nCloud computing  has revolutionized the way organizations handle digital operations. Amazon Web\\nServices (AWS), Microsoft Azure, and Google Cloud Platform (GCP) are the three cloud service\\nproviders  dominating the cloud market worldwide.\\nMost enterprises have moved computing from on-site servers into the cloud and even multi-cloud\\nenvironments , so that they can benefit from features such as:\\nDecreased CapEx\\nReduced infrastructure maintenance\\nIncreased availability  and reliability\\nScalability of an on-demand resource\\nLower operational costs\\nRemote access and facilitated collaboration\\nSupport for multiple devices\\nOptimized infrastructure for speed and performance\\nEnhanced security\\nAccess to the most up-to-date technologyThe big three cloud computing providers all bring experience and expertise to their reliable and\\nfeature-rich platforms. Which is better? AWS vs Microsoft Azure vs Google Cloud?\\nHere are details of each one, along with an Azure, AWS, and GCP comparison that will help you do\\nyour due diligence before making a choice for your company.\\nAmazon Web Services (AWS)\\nMicrosoft Azure\\nGoogle Cloud Platform (GCP)\\nHow to choose between AWS, Microsoft Azure, and Google Cloud\\nUnderstanding Pricing Differences Between AWS, GCP, and Microsoft Azure\\nPros and Cons of AWS, Azure, and GCP\\nAmazon Web Services (AWS)\\nThe current market leader is Amazon Web Services , a subsidiary of Amazon.com, Inc. It is the most\\nmature cloud platform and offers a wide range of services to individual developers, small and large\\nenterprises, and governments.\\nAWS started its life as an internal cloud platform. It evolved into a publicly available, on-demand\\ninternet computing resource in 2006, offering services like Amazon S3 cloud storage and elastic\\ncompute cloud (EC2). AWS now offers more than 200 fully featured services to millions of users. It\\nrakes in one of every three dollars spent on cloud services, with an annual growth rate of 37%,\\naccording to figures published in The Register . It delivered 54% of Amazon’s total operating income  in\\n2023.\\nProminent AWS customers include:\\nExpedia\\nNetflix\\nCoinbase\\nFormula 1\\nCoca Cola\\nIntuit\\nAirbnb\\nLyftCoursera\\nFood and Drug Administration (FDA)\\n(Explore our AWS Guide , a series of articles & tutorials.)\\nMicrosoft Azure\\nMicrosoft Azure is the second-largest cloud platform, but is growing faster than AWS with an annual\\ngrowth rate of 46%, again as measured in The Register . Microsoft has reported  cloud revenue growth\\nof 30% for the quarter ending December 31, 2023. Azure has expanded since its 2010 launch to offer\\nover 200 products and services. \\nAzure, an offering of Microsoft, is particularly tailored to support Microsoft-centric enterprises.\\nMoving to the cloud or a hybrid-cloud environment is easier for these organizations. More than 95%\\nof Fortune 500  companies use Microsoft Azure today.\\nAzure is not limited to Windows-based services. It also supports open-source languages,\\ntechnologies, and platforms, giving anyone the freedom to build and support any application.\\nWell known Azure customers include:\\nDAIMLER AG\\nMcKesson Group\\nAsos\\nCenter of Disease Control (CDC) – US\\nNational Health Service (NHS) – UK\\nHSBC\\nStarbucks\\nWalgreens\\n3M\\nHP\\nMitsubishi Electric\\nRenault\\n(Explore popular Azure certifications .)\\nGoogle Cloud Platform (GCP)\\nCompared to AWS vs Azure, GCP is the smallest of the big three cloud providers.\\nThat said, it is the fastest growing, with a 54% market share growth rate, The Register reports. The\\ncompany expects  the business to grow 20% in 2024.\\nThe GCP currently offers over 200 services spanning computing, networking, big data , and more.\\nToday, GCP consists of services including Google Workspace, enterprise Android, and Chrome OS.\\nNotable GCP customers include:\\nToyota\\nUnilever\\nNintendo\\nSpotifyThe Home Depot\\nTarget\\nTwitter\\nPaypal\\nUPS\\nHow to choose between AWS, Microsoft Azure, and Google Cloud\\nWhen choosing between AWS vs. Microsoft Azure vs. Google Cloud, the first thing to consider is the\\navailability of services in the regions where you operate. Regional availability has a direct impact on\\nperformance, like network latency and speed in transmitting data. Compliance issues also vary by\\nregion, particularly related to cybersecurity.\\nAs of July 25, 2024, here’s where the big three stand:\\nComparing AWS, GCP, and Azure regions and availability\\nWhen choosing a cloud provider, the first thing to consider is its supported regions and availability.\\nThese directly impact the performance of your cloud, due to factors like latency and compliance\\nrequirements, especially when dealing with data.\\nAs of September 2021, here’s where the Big 3 stand:\\nAWS  has 33 geographic regions  with105 availability zones. They plan to add seven more\\nregions and 21 more availability zones in the immediate future. They serve 600+ edge locations\\nand 12 regional edge caches.\\nMicrosoft Azure  runs 64 regions  with 15 under construction. They maintain 126 availability\\nzones with 37 more being built. Microsoft maintains  192 edge locations in global cities with four\\nedge locations in the US government cloud.\\nGCP  has 40 cloud regions  with eight new ones coming soon. They’ve built 121 zones and 187\\nedge locations.\\nEach of these platforms provide specialized cloud solutions for the government (government cloud).\\nBoth AWS and Azure offer specialized services that cater to the Chinese market as well, with data\\ncenters located in China.\\nIn making an Azure, AWS, and GCP comparison, it’s important to note that each covers most of the\\nglobe. All three are also continuing to expand their coverage by adding more regions and zones to\\nmeet the ever-increasing computing demand.\\n(Get an in-depth look at the Big 3 regions & availability .)\\nCommon services of the big three cloud providers\\nAn AWS vs. Azure comparison shows that both have similarly large catalogs of more than 200\\nservices each. GCP is quickly catching up to these leaders. A general breakdown of services is:\\nAWS has the largest catalog of services, topping 250.\\nAzure is a close second, with an impressive set of over 200 artificial intelligence (AI), machine\\nlearning (ML), and analytics services.\\nGCP matches Azure in the number of services they offer.Here are the common service offerings of each cloud platform.\\nComparing AWS, Azure, and GCP compute services\\nThis Azure, AWS, GCP comparison of services chart shows how they compete with various\\ntechnologies across key offerings.\\nComparing AWS, Azure, and GCP database and storage services\\nWhen it comes to storage services, AWS, Azure, and GCP also compete with different database\\ntechnologies and branded storage solutions.Comparing AWS, Azure, and GCP networking services\\nComparing AWS, Azure, and GCP, each has their own way of handling various aspects of managing\\nnetworking services.An\\nAzure, AWS, and GCP comparison shows that they all cover common computing needs. Their\\ndifferences fall into two categories:\\nHow each service is implemented in its cloud platform\\nThe individual features available for each service\\nSpecialized services\\nAn area of significant service differences between AWS, Microsoft Azure, and Google Cloud is in\\nspecialized services. AWS and Azure are comparable, with GCP rapidly catching up.Thes\\ne are only some of the specialized services available on these platforms. AWS customers can even\\ndabble with quantum computing using Amazon Braket .Understanding pricing differences between AWS, GCP, and Microsoft Azure\\nAWS vs Microsoft Azure vs Google Cloud compete on both price and value. Their pricing plans are\\nbased on these factors:\\nCustomer requirements\\nUsage\\nServices used\\nAll three platforms offer competitive pricing plans with additional cost management\\noptions—reserved instances, budgets, and resource optimization—available to all users.\\nThe consensus in the IT community is that Microsoft Azure currently has the lowest on-demand\\npricing, while Amazon tends to come in somewhere around the middle. Enterprise customers\\nalready using Microsoft services (Windows, active directory, MS SQL, etc.) have an advantage when\\nthey move to Azure, as it is significantly cheaper than other cloud providers.\\nEvaluating the big three\\nIn evaluating AWS vs. Azure vs. GCP, you will find that each has pros and cons. We’ve simplified the\\ncomparison for you here:AWS: Pros and Cons\\nAWS: Pros and Cons\\nPros Cons\\n• Most services available, from networking to\\nrobotics\\n• Most mature\\n• Considered the gold standard in cloud reliability\\nand security\\n• More compute capacity vs Azure & GCP\\n• All major software vendors make their programs\\navailable on AWS• Dev/Enterprise support must be purchased\\n• Can overwhelm newcomers with the sheer\\nnumber of services and options\\n• Comparatively limited options for hybrid cloud\\nMICROSOFT AZURE: Pros and Cons\\nPros Cons\\n• Easy integration and migrations for existing\\nMicrosoft services\\n• Many services available, including best-in-class\\nAI, ML, and analytics services\\n• Relatively cheaper for most services vs AWS &\\nGCP\\n• Great support for hybrid cloud strategies• Fewer service offerings vs AWS\\n• Particularly geared towards enterprise\\ncustomers\\nGCP: Pros and Cons\\nPros Cons\\n• Plays nicely with other Google service and\\nproducts\\n• Excellent support for containerized workloads\\n• Global fiber network• Limited services vs AWS & Azure\\n• Limited support for enterprise use casesSumming up the differences between AWS, Azure, and Google Cloud\\nThough AWS is the current market leader in terms of capacity and service, Microsoft and Google are\\ngrowing quickly to challenge that dominance. To compete with AWS, they are building out facilities,\\ninnovating new services, and offering new options in their packages and pricing plans.\\nMicrosoft is challenging AWS by going after the large enterprise market segment. Google is\\ndifferentiating with multiple integrated open-source projects and third-party services.\\nWhich is right for your company? In making an Azure, AWS, GCP comparison, the right answer\\ndepends on your specific use case. In a rapidly evolving cloud technology environment, more\\ncustomers are implementing multi-cloud strategies to make the best use of each provider’s\\nstrengths, without locking themselves to a single one .')]}\n",
            "Summarized Response: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "AWS VS AZURE VS GCP: COMPARING THE BIG 3 CLOUD\n",
            "PLATFORMS\n",
            "The big three of cloud computing platforms\n",
            "Cloud computing  has revolutionized the way organizations handle digital operations. Amazon Web\n",
            "Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) are the three cloud service\n",
            "providers  dominating the cloud market worldwide.\n",
            "Most enterprises have moved computing from on-site servers into the cloud and even multi-cloud\n",
            "environments , so that they can benefit from features such as:\n",
            "Decreased CapEx\n",
            "Reduced infrastructure maintenance\n",
            "Increased availability  and reliability\n",
            "Scalability of an on-demand resource\n",
            "Lower operational costs\n",
            "Remote access and facilitated collaboration\n",
            "Support for multiple devices\n",
            "Optimized infrastructure for speed and performance\n",
            "Enhanced security\n",
            "Access to the most up-to-date technologyThe big three cloud computing providers all bring experience and expertise to their reliable and\n",
            "feature-rich platforms. Which is better? AWS vs Microsoft Azure vs Google Cloud?\n",
            "Here are details of each one, along with an Azure, AWS, and GCP comparison that will help you do\n",
            "your due diligence before making a choice for your company.\n",
            "Amazon Web Services (AWS)\n",
            "Microsoft Azure\n",
            "Google Cloud Platform (GCP)\n",
            "How to choose between AWS, Microsoft Azure, and Google Cloud\n",
            "Understanding Pricing Differences Between AWS, GCP, and Microsoft Azure\n",
            "Pros and Cons of AWS, Azure, and GCP\n",
            "Amazon Web Services (AWS)\n",
            "The current market leader is Amazon Web Services , a subsidiary of Amazon.com, Inc. It is the most\n",
            "mature cloud platform and offers a wide range of services to individual developers, small and large\n",
            "enterprises, and governments.\n",
            "AWS started its life as an internal cloud platform. It evolved into a publicly available, on-demand\n",
            "internet computing resource in 2006, offering services like Amazon S3 cloud storage and elastic\n",
            "compute cloud (EC2). AWS now offers more than 200 fully featured services to millions of users. It\n",
            "rakes in one of every three dollars spent on cloud services, with an annual growth rate of 37%,\n",
            "according to figures published in The Register . It delivered 54% of Amazon’s total operating income  in\n",
            "2023.\n",
            "Prominent AWS customers include:\n",
            "Expedia\n",
            "Netflix\n",
            "Coinbase\n",
            "Formula 1\n",
            "Coca Cola\n",
            "Intuit\n",
            "Airbnb\n",
            "LyftCoursera\n",
            "Food and Drug Administration (FDA)\n",
            "(Explore our AWS Guide , a series of articles & tutorials.)\n",
            "Microsoft Azure\n",
            "Microsoft Azure is the second-largest cloud platform, but is growing faster than AWS with an annual\n",
            "growth rate of 46%, again as measured in The Register . Microsoft has reported  cloud revenue growth\n",
            "of 30% for the quarter ending December 31, 2023. Azure has expanded since its 2010 launch to offer\n",
            "over 200 products and services. \n",
            "Azure, an offering of Microsoft, is particularly tailored to support Microsoft-centric enterprises.\n",
            "Moving to the cloud or a hybrid-cloud environment is easier for these organizations. More than 95%\n",
            "of Fortune 500  companies use Microsoft Azure today.\n",
            "Azure is not limited to Windows-based services. It also supports open-source languages,\n",
            "technologies, and platforms, giving anyone the freedom to build and support any application.\n",
            "Well known Azure customers include:\n",
            "DAIMLER AG\n",
            "McKesson Group\n",
            "Asos\n",
            "Center of Disease Control (CDC) – US\n",
            "National Health Service (NHS) – UK\n",
            "HSBC\n",
            "Starbucks\n",
            "Walgreens\n",
            "3M\n",
            "HP\n",
            "Mitsubishi Electric\n",
            "Renault\n",
            "(Explore popular Azure certifications .)\n",
            "Google Cloud Platform (GCP)\n",
            "Compared to AWS vs Azure, GCP is the smallest of the big three cloud providers.\n",
            "That said, it is the fastest growing, with a 54% market share growth rate, The Register reports. The\n",
            "company expects  the business to grow 20% in 2024.\n",
            "The GCP currently offers over 200 services spanning computing, networking, big data , and more.\n",
            "Today, GCP consists of services including Google Workspace, enterprise Android, and Chrome OS.\n",
            "Notable GCP customers include:\n",
            "Toyota\n",
            "Unilever\n",
            "Nintendo\n",
            "SpotifyThe Home Depot\n",
            "Target\n",
            "Twitter\n",
            "Paypal\n",
            "UPS\n",
            "How to choose between AWS, Microsoft Azure, and Google Cloud\n",
            "When choosing between AWS vs. Microsoft Azure vs. Google Cloud, the first thing to consider is the\n",
            "availability of services in the regions where you operate. Regional availability has a direct impact on\n",
            "performance, like network latency and speed in transmitting data. Compliance issues also vary by\n",
            "region, particularly related to cybersecurity.\n",
            "As of July 25, 2024, here’s where the big three stand:\n",
            "Comparing AWS, GCP, and Azure regions and availability\n",
            "When choosing a cloud provider, the first thing to consider is its supported regions and availability.\n",
            "These directly impact the performance of your cloud, due to factors like latency and compliance\n",
            "requirements, especially when dealing with data.\n",
            "As of September 2021, here’s where the Big 3 stand:\n",
            "AWS  has 33 geographic regions  with105 availability zones. They plan to add seven more\n",
            "regions and 21 more availability zones in the immediate future. They serve 600+ edge locations\n",
            "and 12 regional edge caches.\n",
            "Microsoft Azure  runs 64 regions  with 15 under construction. They maintain 126 availability\n",
            "zones with 37 more being built. Microsoft maintains  192 edge locations in global cities with four\n",
            "edge locations in the US government cloud.\n",
            "GCP  has 40 cloud regions  with eight new ones coming soon. They’ve built 121 zones and 187\n",
            "edge locations.\n",
            "Each of these platforms provide specialized cloud solutions for the government (government cloud).\n",
            "Both AWS and Azure offer specialized services that cater to the Chinese market as well, with data\n",
            "centers located in China.\n",
            "In making an Azure, AWS, and GCP comparison, it’s important to note that each covers most of the\n",
            "globe. All three are also continuing to expand their coverage by adding more regions and zones to\n",
            "meet the ever-increasing computing demand.\n",
            "(Get an in-depth look at the Big 3 regions & availability .)\n",
            "Common services of the big three cloud providers\n",
            "An AWS vs. Azure comparison shows that both have similarly large catalogs of more than 200\n",
            "services each. GCP is quickly catching up to these leaders. A general breakdown of services is:\n",
            "AWS has the largest catalog of services, topping 250.\n",
            "Azure is a close second, with an impressive set of over 200 artificial intelligence (AI), machine\n",
            "learning (ML), and analytics services.\n",
            "GCP matches Azure in the number of services they offer.Here are the common service offerings of each cloud platform.\n",
            "Comparing AWS, Azure, and GCP compute services\n",
            "This Azure, AWS, GCP comparison of services chart shows how they compete with various\n",
            "technologies across key offerings.\n",
            "Comparing AWS, Azure, and GCP database and storage services\n",
            "When it comes to storage services, AWS, Azure, and GCP also compete with different database\n",
            "technologies and branded storage solutions.Comparing AWS, Azure, and GCP networking services\n",
            "Comparing AWS, Azure, and GCP, each has their own way of handling various aspects of managing\n",
            "networking services.An\n",
            "Azure, AWS, and GCP comparison shows that they all cover common computing needs. Their\n",
            "differences fall into two categories:\n",
            "How each service is implemented in its cloud platform\n",
            "The individual features available for each service\n",
            "Specialized services\n",
            "An area of significant service differences between AWS, Microsoft Azure, and Google Cloud is in\n",
            "specialized services. AWS and Azure are comparable, with GCP rapidly catching up.Thes\n",
            "e are only some of the specialized services available on these platforms. AWS customers can even\n",
            "dabble with quantum computing using Amazon Braket .Understanding pricing differences between AWS, GCP, and Microsoft Azure\n",
            "AWS vs Microsoft Azure vs Google Cloud compete on both price and value. Their pricing plans are\n",
            "based on these factors:\n",
            "Customer requirements\n",
            "Usage\n",
            "Services used\n",
            "All three platforms offer competitive pricing plans with additional cost management\n",
            "options—reserved instances, budgets, and resource optimization—available to all users.\n",
            "The consensus in the IT community is that Microsoft Azure currently has the lowest on-demand\n",
            "pricing, while Amazon tends to come in somewhere around the middle. Enterprise customers\n",
            "already using Microsoft services (Windows, active directory, MS SQL, etc.) have an advantage when\n",
            "they move to Azure, as it is significantly cheaper than other cloud providers.\n",
            "Evaluating the big three\n",
            "In evaluating AWS vs. Azure vs. GCP, you will find that each has pros and cons. We’ve simplified the\n",
            "comparison for you here:AWS: Pros and Cons\n",
            "AWS: Pros and Cons\n",
            "Pros Cons\n",
            "• Most services available, from networking to\n",
            "robotics\n",
            "• Most mature\n",
            "• Considered the gold standard in cloud reliability\n",
            "and security\n",
            "• More compute capacity vs Azure & GCP\n",
            "• All major software vendors make their programs\n",
            "available on AWS• Dev/Enterprise support must be purchased\n",
            "• Can overwhelm newcomers with the sheer\n",
            "number of services and options\n",
            "• Comparatively limited options for hybrid cloud\n",
            "MICROSOFT AZURE: Pros and Cons\n",
            "Pros Cons\n",
            "• Easy integration and migrations for existing\n",
            "Microsoft services\n",
            "• Many services available, including best-in-class\n",
            "AI, ML, and analytics services\n",
            "• Relatively cheaper for most services vs AWS &\n",
            "GCP\n",
            "• Great support for hybrid cloud strategies• Fewer service offerings vs AWS\n",
            "• Particularly geared towards enterprise\n",
            "customers\n",
            "GCP: Pros and Cons\n",
            "Pros Cons\n",
            "• Plays nicely with other Google service and\n",
            "products\n",
            "• Excellent support for containerized workloads\n",
            "• Global fiber network• Limited services vs AWS & Azure\n",
            "• Limited support for enterprise use casesSumming up the differences between AWS, Azure, and Google Cloud\n",
            "Though AWS is the current market leader in terms of capacity and service, Microsoft and Google are\n",
            "growing quickly to challenge that dominance. To compete with AWS, they are building out facilities,\n",
            "innovating new services, and offering new options in their packages and pricing plans.\n",
            "Microsoft is challenging AWS by going after the large enterprise market segment. Google is\n",
            "differentiating with multiple integrated open-source projects and third-party services.\n",
            "Which is right for your company? In making an Azure, AWS, GCP comparison, the right answer\n",
            "depends on your specific use case. In a rapidly evolving cloud technology environment, more\n",
            "customers are implementing multi-cloud strategies to make the best use of each provider’s\n",
            "strengths, without locking themselves to a single one .\n",
            "\n",
            "Question: What is AWS?\n",
            "Helpful Answer: AWS stands for Amazon Web Services, which is a subsidiary of Amazon.com, Inc. It is the most mature cloud platform and offers a wide range of services to individual developers, small and large enterprises, and governments. AWS started its life as an internal cloud platform and evolved into a publicly available, on-demand internet computing resource in 2006, offering services like Amazon S3 cloud storage and elastic compute cloud (EC2). AWS now offers more than 200 fully featured services to millions of users. It raked in one of every three dollars spent on cloud services, with an annual growth rate of 37%, according to figures published in The Register. It delivered 54% of Amazon’s total operating income in 2023. Prominent AWS customers include Expedia, Netflix, Coinbase, Formula 1, Coca Cola, Intuit, Airbnb, Lyft, Coursera, and the Food and Drug Administration (FDA).\n",
            "\n",
            "Note: Ignoring source document content...\n",
            "Source Document Metadata: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final version of working code"
      ],
      "metadata": {
        "id": "RbrCW504Hl-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Step 1: Load and extract text from the PDF\n",
        "file_path = \"/content/Suraj J.pdf\"\n",
        "reader = PdfReader(file_path)\n",
        "\n",
        "# Extract text from all pages\n",
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "    text += page.extract_text()\n",
        "\n",
        "# Load the extracted text into a document\n",
        "document = Document(page_content=text)\n",
        "\n",
        "# Step 2: Generate embeddings using a pre-trained model\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "documents = [document]\n",
        "\n",
        "# Index the document using FAISS\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "# Step 3: Initialize the language model (e.g., GPT from Hugging Face)\n",
        "llm = HuggingFaceHub(repo_id=\"gpt2\", model_kwargs={\"temperature\": 0.5, \"max_length\": 150}, huggingfacehub_api_token=\"Enter your API token\")\n",
        "\n",
        "# Step 4: Create the retrieval-based QA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    return_source_documents=False\n",
        ")\n",
        "\n",
        "while True:\n",
        "  # Step 5: Test with a user query\n",
        "  query = input(\"Enter your Query:\")\n",
        "  response = qa_chain({\"query\": query})\n",
        "\n",
        "  # Step 6: Print the response\n",
        "  result = response['result']\n",
        "  print(\"Response:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aMiHiVdgCfZb",
        "outputId": "d26fad73-f208-4887-dd65-2df695aa93b0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Query:is suraj ai engineer?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "suraj1642001@gmail.com  Suraj J +91 7022584746  \n",
            " \n",
            "AI Engineer with 1.7 years of professional experience and a BE in Computer Science and Engineering (2023). Specialize s in building \n",
            "and fine -tuning NLP, Computer -vision, and large language models (LLMs), with expertise in Lang Chain -based agent and chain \n",
            "development.  Proficient in developing and deploying machine learning and deep learning models,  along with creating robust data \n",
            "pipelines.  \n",
            "EDUCATION  \n",
            "Bachelor  of Engineer,  Computer  Science  & Engineering,  GPA: 8.14 /10.00  Aug 2019 — May 2023 \n",
            "EXPERIENCE  \n",
            "AI Engineer  Feb 2024 — Present  \n",
            "Atharvo  Technology  Pvt Ltd  Bangalore  \n",
            "AI Models:  Contributed to building LLM -based chains and agents, fine -tuning, and integrating NLP, computer vision, machine learning, \n",
            "and LLM models into applications. Also experienced in API development for seamless model integration.  \n",
            "Data Workflow pipeline : Developed end -to-end data pipelines to efficiently fetch, process, and store data from multiple sources  \n",
            "utilizing AWS  services and Orchestrated Dataflow on Airflow.  \n",
            "Tech Stack  Used:  Git,Github  Python, Flask,  Lang chain , Hugging Face Models , Airflow,  Docker, AWS– S3 Bucket,  Lambda  Kafka,  Ec2. \n",
            "Jr. Data Engineer  Jul 2023 — Jan 2024 \n",
            "Diggibyte  Technology  Pvt Ltd  Bangalore  \n",
            "• Data Transformation  : Developed Py thon scripts to efficiently transform raw data into structured, actionable formats, optimiz ed data \n",
            "processing workflows on Databricks.  \n",
            "• ETL Pipeline  : Developed   and Orchestrated multiple End to End pipeline s capable  to efficiently  performing the Data Operations in the \n",
            "Data Workflow on schedule time period.  \n",
            "• Tech Stack Used:  Git, GitHub,  AWS Cloud  services  – S3 Bucket, EC2,Lambda Function,  Data-Bricks,  Python,  SQL, Airflow.  \n",
            "PROJECTS  \n",
            " AI Chatbot  - Link \n",
            "• LLM Model : Utilized Gpt -2 LLM model from Hugging face to generate responses to users query integrated using python code.  \n",
            "• API : Developed Flask Api’s to fetch the requests , tokenize prompt and send back the generated responses to the frontend.  \n",
            "Customer  Classification  2 layered  Neural  Network - Link \n",
            "• Data Preprocessing:  As Data Engineering  part I was responsible  for extracting  raw data from the multiple  sources  ,transform  them \n",
            "by eliminating noisy data and Feature Engineer it for the best usage for development.  \n",
            "• ML Model  : Developed  2 layered  Neural  Network  Model  used forward  propagation,  backward  propagation  techniques  with \n",
            "sigmoid  curve  function  for efficient predictions  also compared  it with  the accuracy score  of other  ML Algorithms.  \n",
            " Brain Tumor Detection from Scanned reports - Link \n",
            "• Model Development & Evaluation : Developed CNN Model on pytorch framework that can process the uploaded image and \n",
            "detect the tumors in the scanned photos.   \n",
            "• Data Preprocessing:  As Data Engineering part I was responsible for extracting raw data from the different sources  \n",
            ",transform them by eliminating noisy data and Feature Engineer it for the best usage for development.  \n",
            "SKILLS  \n",
            "Programming  Python,  SQL \n",
            "Big Data Hadoop,  Spark,  AWS Cloud  -- S3 Bucket,  Athena,  Lambda  function,  Redshift , Airflow , Kafka, Docker.  \n",
            "Algorithms  Linear  Regression,  Logistic  Regression,  Decision  Trees,  Random  Forest,  SVM. CNN, RNN,LSTM, GAN. \n",
            "Models            GPT-2, T5, BART , Hugging Face Models -NLP, Comp uter vision . \n",
            "Libraries           Scikit -Learn,  Pytorch, TensorFlow , Lang chain  \n",
            "Version  Control   Git, GitHub.  \n",
            "IDE VS-Code,  Google -Colab, Jupyter Notebook.  \n",
            "CERTIFICATIONS  \n",
            "- Databricks  Certifications  : Databricks  fundamentals,  Gen-AI Fundamentals,  AWS Platform  Architect.  \n",
            "- Salesforce -Trailhead  : Completed  AWS cloud  for technical  professionals  course.  \n",
            "- Certified  from “British  Airways”,”JP  Morgan  Chase  & Co.” for successfully  completing  the Virtual  job Simulation.  \n",
            "- NVDIA Certifications :  Building RAG Agents w ith LLMs , Generative AI , Applications Development with LLM . \n",
            "\n",
            "Question: is suraj ai engineer?\n",
            "Helpful Answer: Yes, Suraj is an AI Engineer as stated in his resume. He has experience in building and fine-tuning NLP, computer vision, and large language models (LLMs), as well as developing and deploying machine learning and deep learning models.\n",
            "Enter your Query:can suraj be data engineer?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "suraj1642001@gmail.com  Suraj J +91 7022584746  \n",
            " \n",
            "AI Engineer with 1.7 years of professional experience and a BE in Computer Science and Engineering (2023). Specialize s in building \n",
            "and fine -tuning NLP, Computer -vision, and large language models (LLMs), with expertise in Lang Chain -based agent and chain \n",
            "development.  Proficient in developing and deploying machine learning and deep learning models,  along with creating robust data \n",
            "pipelines.  \n",
            "EDUCATION  \n",
            "Bachelor  of Engineer,  Computer  Science  & Engineering,  GPA: 8.14 /10.00  Aug 2019 — May 2023 \n",
            "EXPERIENCE  \n",
            "AI Engineer  Feb 2024 — Present  \n",
            "Atharvo  Technology  Pvt Ltd  Bangalore  \n",
            "AI Models:  Contributed to building LLM -based chains and agents, fine -tuning, and integrating NLP, computer vision, machine learning, \n",
            "and LLM models into applications. Also experienced in API development for seamless model integration.  \n",
            "Data Workflow pipeline : Developed end -to-end data pipelines to efficiently fetch, process, and store data from multiple sources  \n",
            "utilizing AWS  services and Orchestrated Dataflow on Airflow.  \n",
            "Tech Stack  Used:  Git,Github  Python, Flask,  Lang chain , Hugging Face Models , Airflow,  Docker, AWS– S3 Bucket,  Lambda  Kafka,  Ec2. \n",
            "Jr. Data Engineer  Jul 2023 — Jan 2024 \n",
            "Diggibyte  Technology  Pvt Ltd  Bangalore  \n",
            "• Data Transformation  : Developed Py thon scripts to efficiently transform raw data into structured, actionable formats, optimiz ed data \n",
            "processing workflows on Databricks.  \n",
            "• ETL Pipeline  : Developed   and Orchestrated multiple End to End pipeline s capable  to efficiently  performing the Data Operations in the \n",
            "Data Workflow on schedule time period.  \n",
            "• Tech Stack Used:  Git, GitHub,  AWS Cloud  services  – S3 Bucket, EC2,Lambda Function,  Data-Bricks,  Python,  SQL, Airflow.  \n",
            "PROJECTS  \n",
            " AI Chatbot  - Link \n",
            "• LLM Model : Utilized Gpt -2 LLM model from Hugging face to generate responses to users query integrated using python code.  \n",
            "• API : Developed Flask Api’s to fetch the requests , tokenize prompt and send back the generated responses to the frontend.  \n",
            "Customer  Classification  2 layered  Neural  Network - Link \n",
            "• Data Preprocessing:  As Data Engineering  part I was responsible  for extracting  raw data from the multiple  sources  ,transform  them \n",
            "by eliminating noisy data and Feature Engineer it for the best usage for development.  \n",
            "• ML Model  : Developed  2 layered  Neural  Network  Model  used forward  propagation,  backward  propagation  techniques  with \n",
            "sigmoid  curve  function  for efficient predictions  also compared  it with  the accuracy score  of other  ML Algorithms.  \n",
            " Brain Tumor Detection from Scanned reports - Link \n",
            "• Model Development & Evaluation : Developed CNN Model on pytorch framework that can process the uploaded image and \n",
            "detect the tumors in the scanned photos.   \n",
            "• Data Preprocessing:  As Data Engineering part I was responsible for extracting raw data from the different sources  \n",
            ",transform them by eliminating noisy data and Feature Engineer it for the best usage for development.  \n",
            "SKILLS  \n",
            "Programming  Python,  SQL \n",
            "Big Data Hadoop,  Spark,  AWS Cloud  -- S3 Bucket,  Athena,  Lambda  function,  Redshift , Airflow , Kafka, Docker.  \n",
            "Algorithms  Linear  Regression,  Logistic  Regression,  Decision  Trees,  Random  Forest,  SVM. CNN, RNN,LSTM, GAN. \n",
            "Models            GPT-2, T5, BART , Hugging Face Models -NLP, Comp uter vision . \n",
            "Libraries           Scikit -Learn,  Pytorch, TensorFlow , Lang chain  \n",
            "Version  Control   Git, GitHub.  \n",
            "IDE VS-Code,  Google -Colab, Jupyter Notebook.  \n",
            "CERTIFICATIONS  \n",
            "- Databricks  Certifications  : Databricks  fundamentals,  Gen-AI Fundamentals,  AWS Platform  Architect.  \n",
            "- Salesforce -Trailhead  : Completed  AWS cloud  for technical  professionals  course.  \n",
            "- Certified  from “British  Airways”,”JP  Morgan  Chase  & Co.” for successfully  completing  the Virtual  job Simulation.  \n",
            "- NVDIA Certifications :  Building RAG Agents w ith LLMs , Generative AI , Applications Development with LLM . \n",
            "\n",
            "Question: can suraj be data engineer?\n",
            "Helpful Answer: Based on Suraj's provided resume, he has experience as a Jr. Data Engineer at Diggibyte Technology Pvt Ltd from July 2023 to January 2024. During this time, he developed Python scripts for data transformation, created and orchestrated ETL pipelines, and worked with tools like AWS Cloud services, DataBricks, Python, SQL, and Airflow. Therefore, yes, Suraj can be considered a Data Engineer.\n",
            "Enter your Query:certificates suraj has completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-ce5b1756a126>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;31m# Step 5: Test with a user query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your Query:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;31m# Step 6: Print the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    387\u001b[0m         }\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/retrieval_qa/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         answer = self.combine_documents_chain.run(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0minput_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m             return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    612\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    387\u001b[0m         }\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/combine_documents/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Other keys are assumed to be needed for LLM prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mother_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         output, extra_return_dict = self.combine_docs(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mother_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/combine_documents/stuff.py\u001b[0m in \u001b[0;36mcombine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Call predict on the LLM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     async def acombine_docs(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \"\"\"\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    387\u001b[0m         }\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    139\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    759\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                 )\n\u001b[1;32m    962\u001b[0m             ]\n\u001b[0;32m--> 963\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    964\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             output = (\n\u001b[0;32m--> 784\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    785\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1521\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m             text = (\n\u001b[0;32m-> 1523\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1524\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/llms/huggingface_hub.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_model_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         response = self.client.post(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mwarning_message\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarning_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprovider_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprovider_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprovider_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         return self._inner_post(\n\u001b[0m\u001b[1;32m    273\u001b[0m             request_parameters=RequestParameters(\n\u001b[1;32m    274\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36m_inner_post\u001b[0;34m(self, request_parameters, stream)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_as_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata_as_binary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                     response = get_session().post(\n\u001b[0m\u001b[1;32m    313\u001b[0m                         \u001b[0mrequest_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                         \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;34m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_AMZN_TRACE_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N_G8du8lFs7P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}